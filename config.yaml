data:
    datasets_used_per_step: 128
    interleaved_datasets: 256
    parallel_workers: 128
    prefetch_buffer: 2
dims:
    sizes:
        sequence: 65536
        batch: 32
        depth: 4
        features_per_head: 256
optimizer:
    exponential_decay: 1.0e-05
    gradient_clip: 0.001
    learning_rate: 0.01
    warmup_end: 4096
training:
    device_steps: 32
    device_unroll: 1
    trace:
        do_trace: false
        start_step: 2
        stop_step: 8
model:
    feed_forward_factor: 2