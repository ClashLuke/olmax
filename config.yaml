data:
    datasets_used_per_step: 2
    deterministic: true
    interleaved_datasets: 2
    parallel_workers: 2
    path: /home/lucas/PycharmProjects/Olmax/data/
    prefetch_buffer: 1
    seed: 0
    shuffle_buffer_gb: 0
dims:
    batch: 256
    depth: 1
    features: 4096
    memory_features: 128
    memory_heads: 8
    memory_slots: 16384
    memory_slots_per_head: 4
    pointwise_features: 1024
    sequence: 1024
    vocab: 256
fail_on_missing_parameter: true
global_prefix: ''
model:
    autoregressive: true
    computation_dtype: bfloat16
    norm:
        eps: 1.0e-16
    storage_dtype: float32
name_cache_offsets: {}
optimizer:
    adam_beta1: 0.1
    adam_beta2: 0.01
    epsilon: 1.0e-16
    exponential_decay: 7.0e-06
    gradient_clip: 0.001
    gradient_noise_factor: 0.0001
    graft_to_sign: false
    learning_rate: 0.00001
    momentum_dtype: float32
    momentum_type: debiased
    warmup_end: 1024
    weight_decay: 0.0001
parameter_usages: {}
seed: 0
training:
    checkpoint_interval: 10000000
    checkpoint_load_path: ''
    checkpoint_path: /home/lucas/PycharmProjects/Olmax/checkpoint
    debug: false
    device_steps: 1
    device_unroll: 1
    do_checkpoint: true
    steps: 65536
    trace:
        do_trace: true
        output_path: trace
        start_step: 16
        stop_step: 80
    z_loss: 0
wandb:
    entity: homebrewnlp
    group: rnn-gated
    id: 34wfw3kv1j7b3vi6bhb1o0l5d0b906ki8
    median_sizes:
    - 64
    - 256
    - 1024
    name: rnn-bwd-every-step
    project: gpt
