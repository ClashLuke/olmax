program: main.py
method: bayes
metric:
  name: Loss/Current
  goal: minimize
command:
    - ${env}
    - python3
    - ${program}
    - ${args}
parameters:
  optimizer.weight_decay:
    distribution: log_uniform
    min: -6
    max: -1
  optimizer.adam_beta2:
    distribution: log_uniform
    min: -9
    max: -2
  optimizer.adam_beta1:
    distribution: log_uniform
    min: -9
    max: -2
  optimizer.gradient_clip:
    distribution: log_uniform
    min: -9
    max: -2
  optimizer.learning_rate:
    distribution: log_uniform
    min: -9
    max: -2
  optimizer.warmup_end:
    distribution: q_log_uniform
    min: 4
    max: 10
  optimizer.momentum_beta:
    distribution: log_uniform
    min: -6
    max: -1
  dims.sizes.full_conv_kernel:
    distribution: q_log_uniform
    min: 0
    max: 5
  dims.sizes.depthwise_conv_kernel:
    distribution: q_log_uniform
    min: 0
    max: 8
  dims.sizes.depth:
    distribution: q_log_uniform
    min: 0
    max: 6
  dims.sizes.features_per_head:
    distribution: q_log_uniform
    min: 5
    max: 7
    q: 128
  dims.sizes.batch:
    distribution: q_log_uniform
    min: 2
    max: 5
    q: 8
  model.rezero_learning_rate_scale:
    distribution: log_uniform
    min: -9
    max: 0
  model.group_linear_factor:
    distribution: q_log_uniform
    min: 0
    max: 2
  model.leaky_relu_slope:
    distribution: log_uniform
    min: -6
    max: 1
  training.z_loss:
    distribution: log_uniform
    min: -9
    max: 1
  model.weight_sharing:
    distribution: categorical
    values:
      - yes
      - no