program: main.py
method: bayes
metric:
  name: Loss/Current
  goal: minimize
command:
    - ${env}
    - python3
    - ${program}
    - ${args}
parameters:
  optimizer.weight_decay:
    distribution: log_uniform_values
    min: 0.0001
    max: 1
  optimizer.adam_beta2:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.2
  optimizer.adam_beta1:
    distribution: log_uniform_values
    min: 0.001
    max: 0.4
  optimizer.gradient_clip:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.5
  optimizer.learning_rate:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.1
  optimizer.warmup_end:
    distribution: q_log_uniform_values
    min: 128
    max: 65536
  optimizer.momentum_beta:
    distribution: log_uniform_values
    min: 0.001
    max: 0.3
  dims.sizes.full_conv_kernel:
    distribution: q_log_uniform_values
    min: 1
    max: 128
  dims.sizes.depthwise_conv_kernel:
    distribution: q_log_uniform_values
    min: 1
    max: 2048
  dims.sizes.depth:
    distribution: q_log_uniform_values
    min: 1
    max: 256
  dims.sizes.features_per_head:
    distribution: q_log_uniform_values
    min: 128
    max: 1024
    q: 128
  dims.sizes.batch:
    distribution: q_log_uniform_values
    min: 8
    max: 128
    q: 8
  model.rezero_learning_rate_scale:
    distribution: log_uniform_values
    min: 0.0001
    max: 2
  model.group_linear_factor:
    distribution: q_log_uniform_values
    min: 1
    max: 8
  model.leaky_relu_slope:
    distribution: log_uniform_values
    min: 0.001
    max: 2
  training.z_loss:
    distribution: log_uniform_values
    min: 0.0001
    max: 2
  model.weight_sharing:
    distribution: categorical
    values:
      - yes
      - no